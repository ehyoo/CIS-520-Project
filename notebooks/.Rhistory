v.hat.strat.low <- compute.variance.summation.component(190, 21, 190+407+811, 0.037)
v.hat.strat.middle <- compute.variance.summation.component(407, 14, 190+407+811, 0.052)
v.hat.strat.high <- compute.variance.summation.component(811, 22, 190+407+811, 0.070)
v.hat.y.strat <- sum(c(v.hat.strat.low, v.hat.strat.middle, v.hat.strat.high))
v.hat.y.strat
se.y.hat.strat <- sqrt(v.hat.y.strat)
se.y.hat.strat
# Strata Pops.
N.low <- 190
N.middle <- 407
N.high <- 811
N.vec <- c(N.low, N.middle, N.high)
N <- sum(N.vec)
# Strata sample means
y.bar.low <- 3.925
y.bar.middle <- 3.938
y.bar.high <- 3.942
y.vec <- c(y.bar.low, y.bar.middle, y.bar.high)
# Computing our estimated population mean
y.hat.str <- sum((N.vec/N) * y.vec)
y.hat.str
rm(list=ls())
# Strata Pops.
N.low <- 190
N.middle <- 407
N.high <- 811
N.vec <- c(N.low, N.middle, N.high)
N <- sum(N.vec)
# Strata sample means
y.bar.low <- 3.925
y.bar.middle <- 3.938
y.bar.high <- 3.942
y.vec <- c(y.bar.low, y.bar.middle, y.bar.high)
# Computing our estimated population mean
y.hat.str <- sum((N.vec/N) * y.vec)
y.hat.str
n.low <- 21
n.middle <- 14
n.high <- 22
s.low <- 0.037
s.middle <- 0.052
s.high <- 0.070
# Computing \hat{V}(\bar{y}_{strat})
compute.variance.summation.component <- function(N.h, n.h, N, s.h) {
pt.1 <- 1 - n.h/N.h
pt.2 <- (N.h/N)^2
pt.3 <- (s.h^2)/n.h
return(pt.1 * pt.2 * pt.3)
}
v.hat.strat.low <- compute.variance.summation.component(190, 21, 190+407+811, 0.037)
v.hat.strat.middle <- compute.variance.summation.component(407, 14, 190+407+811, 0.052)
v.hat.strat.high <- compute.variance.summation.component(811, 22, 190+407+811, 0.070)
v.hat.y.strat <- sum(c(v.hat.strat.low, v.hat.strat.middle, v.hat.strat.high))
# >> 8.85288e-05
se.y.hat.strat <- sqrt(v.hat.y.strat)
# >> 0.009408975
# Finally, getting our 95% confidence interval
lower.ci <- y.hat.str - 1.96 * se.y.hat.strat
upper.ci <- y.hat.str + 1.96 * se.y.hat.strat
c(lower.ci, upper.ci)
sum(1,2)
budget <- 250
N.A <- 1000
N.B <- 720
c.A <- 5
c.B <- 10
p.A <- 0.15
p.B <- 0.03
S.A <- sqrt(p.A * (1-p.A) * (N.A/(N.A - 1)))
S.B <- sqrt(p.B * (1-p.B) * (N.B/(N.B - 1)))
numerator.op.A <- (N.A * S.A)/sqrt(c.A)
numerator.op.B <- (N.B * S.B)/sqrt(c.B)
numerator.total.samp.size <- (budget - 0) * sum(numerator.op.a, numerator.op.b)
budget <- 250
N.A <- 1000
N.B <- 720
c.A <- 5
c.B <- 10
p.A <- 0.15
p.B <- 0.03
S.A <- sqrt(p.A * (1-p.A) * (N.A/(N.A - 1)))
S.B <- sqrt(p.B * (1-p.B) * (N.B/(N.B - 1)))
numerator.op.A <- (N.A * S.A)/sqrt(c.A)
numerator.op.B <- (N.B * S.B)/sqrt(c.B)
numerator.total.samp.size <- (budget - 0) * sum(numerator.op.A, numerator.op.B)
denom.total.samp.size <- sum(N.A * S.A * sqrt(c.A), N.B * S.B * sqrt(c.B))
total.affordable.sample <- numerator.total.samp.size/denom.total.samp.size
total.affordable.sample
floor(total.affordable.sample)
budget <- 250
N.A <- 1000
N.B <- 720
c.A <- 5
c.B <- 10
p.A <- 0.15
p.B <- 0.03
S.A <- sqrt(p.A * (1-p.A) * (N.A/(N.A - 1)))
S.B <- sqrt(p.B * (1-p.B) * (N.B/(N.B - 1)))
numerator.op.A <- (N.A * S.A)/sqrt(c.A)
numerator.op.B <- (N.B * S.B)/sqrt(c.B)
denom.op.A.B <- sum(numerator.op.A, numerator.op.B)
numerator.total.samp.size <- (budget - 0) * sum(numerator.op.A, numerator.op.B)
denom.total.samp.size <- sum(N.A * S.A * sqrt(c.A), N.B * S.B * sqrt(c.B))
total.affordable.sample <- floor(numerator.total.samp.size/denom.total.samp.size) # floor to not go over the budget
total.affordable.sample
op.A.sample <- total.affordable.sample * (numerator.op.A/denom.op.A.B)
op.A.sample
op.B.sample <- total.affordable.sample * (numerator.op.B/denom.op.A.B)
op.B.sample
budget <- 250
N.A <- 1000
N.B <- 720
c.A <- 5
c.B <- 10
p.A <- 0.15
p.B <- 0.03
S.A <- sqrt(p.A * (1-p.A) * (N.A/(N.A - 1)))
S.B <- sqrt(p.B * (1-p.B) * (N.B/(N.B - 1)))
numerator.op.A <- (N.A * S.A)/sqrt(c.A)
numerator.op.B <- (N.B * S.B)/sqrt(c.B)
denom.op.A.B <- sum(numerator.op.A, numerator.op.B)
numerator.total.samp.size <- (budget - 0) * sum(numerator.op.A, numerator.op.B)
denom.total.samp.size <- sum(N.A * S.A * sqrt(c.A), N.B * S.B * sqrt(c.B))
total.affordable.sample <- numerator.total.samp.size/denom.total.samp.size # floor to not go over the budget
total.affordable.sample
op.A.sample <- total.affordable.sample * (numerator.op.A/denom.op.A.B)
op.A.sample
op.B.sample <- total.affordable.sample * (numerator.op.B/denom.op.A.B)
op.B.sample
5*33.64 + 10*8.18
six.data <- read.table("sixthgrade.csv", header=T, sep=",")
summary(sixdata$score)
summary(six.data$score)
tapply(six.data$score, six.data$track,summary)
library(ggplot2)
myplot<-ggplot(data = sixdata, aes(x = as.factor(track), y = score))+geom_boxplot()
library(ggplot2)
six.data.boxplots <- ggplot(data = six.data, aes(x = as.factor(track), y = score))+geom_boxplot()
six.data.boxplots
six.fpc <- 56 * (six.data$track==1) + 80 * (six.data$track==2) + 64 * (six.data$track==3)
six.fpc
head(six.data)
six.fpc <- 56 * (six.data$track==1) + 80 * (six.data$track==2) + 64 * (six.data$track==3)
six.weights <- (56/14) * (six.data$track==1) + (80/20) * (six.data$track==2) + (64/16)*(six.data$track==3)
six.data2 <- cbind(six.data, six.fpc, six.weights)
mydesign<-svydesign(id=~1,
weights=~six.weights,
fpc=~six.fpc,
strata=~track,
data=six.data2)
size(six.data)
dim(six.data)
library(survey)
radon.df <- read.csv("radon.csv")
size(radon.df)
dim(radon.df)
radon.df
six.data
svymean(~score, six.svy.design)
six.fpc <- 56 * (six.data$track==1) + 80 * (six.data$track==2) + 64 * (six.data$track==3)
six.weights <- (56/14) * (six.data$track==1) + (80/20) * (six.data$track==2) + (64/16)*(six.data$track==3)
six.data2 <- cbind(six.data, six.fpc, six.weights)
six.svy.design <- svydesign(id=~1,
weights=~six.weights,
fpc=~six.fpc,
strata=~track,
data=six.data2)
svymean(~score, six.svy.design)
svymean(~score, six.svy.design, deff=TRUE)
six.fpc <- 56 * (six.data$track==1) + 80 * (six.data$track==2) + 64 * (six.data$track==3)
six.weights <- (56/14) * (six.data$track==1) + (80/20) * (six.data$track==2) + (64/16)*(six.data$track==3)
six.data2 <- cbind(six.data, six.fpc, six.weights)
six.svy.design <- svydesign(id=~1,
fpc=~six.fpc,
strata=~track,
data=six.data2)
n
svymean(~score, six.svy.design)
six.fpc <- 56 * (six.data$track==1) + 80 * (six.data$track==2) + 64 * (six.data$track==3)
six.weights <- (56/14) * (six.data$track==1) + (80/20) * (six.data$track==2) + (64/16)*(six.data$track==3)
six.data2 <- cbind(six.data, six.fpc, six.weights)
six.svy.design <- svydesign(id=~1,
weights=~six.weights,
fpc=~six.fpc,
strata=~track,
data=six.data2)
svymean(~score, six.svy.design)
six.fpc <- 56 * (six.data$track==1) + 80 * (six.data$track==2) + 64 * (six.data$track==3)
six.weights <- (56/14) * (six.data$track==1) + (80/20) * (six.data$track==2) + (64/16)*(six.data$track==3)
six.data2 <- cbind(six.data, six.fpc, six.weights)
six.svy.design <- svydesign(id=~1,
fpc=~six.fpc,
strata=~track,
data=six.data2)
svymean(~score, six.svy.design)
svymean(~score, six.svy.design, deff=TRUE)
total.pop.six <- 56 + 80 + 64 # given data
six.fpc.simple <- rep(total.pop.six, nrow(six.data2))
six.data2$six.fpc.simple <- six.fpc.simple
srs.simple.six.design <- svydesign(id=~1, fpc=~six.fpc.simple, data=six.data2)
svymean(~score, srs.simple.six.design)
1.2165/2.7571
six.fpc.simple
six.data <- read.table("sixthgrade.csv", header=T, sep=",") # starting fresh
total.pop.six <- 56 + 80 + 64 # given data
six.fpc.simple <- rep(total.pop.six, nrow(six.data))
six.data$six.fpc.simple <- six.fpc.simple
srs.simple.six.design <- svydesign(id=~1, fpc=~six.fpc.simple, data=six.data)
```{r}
svymean(~score, srs.simple.six.design)
six.data <- read.table("sixthgrade.csv", header=T, sep=",")
summary(six.data$score)
tapply(six.data$score, six.data$track,summary)
1.2165^2/2.7571^2
clarivate.status.df <- read.csv('../data/wrds_clarivate_status.csv', stringsAsFactors = FALSE)
# Focus on dates from the US
clarivate.status.df.us.exclusive <- clarivate.status.df[clarivate.status.df$CountryID == "US", ]
# Get all unique rows to get our list, and then query to get our list of unique drugs who have reached at least phase 1.
unique.rows.clarivate.df <- unique(clarivate.status.df.us.exclusive[ ,c("DrugID", "DrugName", "DevelopmentStatus", "StatusDate")])
phase.1.drugs.with.date.df <- unique.rows.clarivate.df[unique.rows.clarivate.df$DevelopmentStatus=="Phase 1 Clinical", ]
phase.1.and.above.drugs.with.date <- unique.rows.clarivate.df[unique.rows.clarivate.df$DevelopmentStatus=="Phase 1 Clinical" |
unique.rows.clarivate.df$DevelopmentStatus=="Phase 2 Clinical" |
unique.rows.clarivate.df$DevelopmentStatus=="Phase 3 Clinical" |
unique.rows.clarivate.df$DevelopmentStatus=="Pre-registration" |
unique.rows.clarivate.df$DevelopmentStatus=="Registered" |
unique.rows.clarivate.df$DevelopmentStatus=="Launched", ]
#### Step 2: Load in SMILES data and join
full.processed.clarivate.df <- read.csv("../processed_data/wrds_clarivate_analytics_parsed_chem_structure_data_set.csv", stringsAsFactors = FALSE)
smiles.with.phase1.and.above.dates.df <- merge(x = full.processed.clarivate.df, y=phase.1.and.above.drugs.with.date, by="DrugName")
# all.smiles.df is the smiles data for all drugs, regardless of status
# indices.phase.1.plus is the indices of all.smiles.df that have reached phase1 and above.
all.smiles.df <- merge(x = full.processed.clarivate.df, y=clarivate.status.df.us.exclusive, by="DrugName")
indices.phase.1.plus <- which(all.smiles.df$DrugName %in% smiles.with.phase1.and.above.dates.df$DrugName)
smiles.phase.1.plus.df <- all.smiles.df[indices.phase.1.plus, ]
test.func <- function(x) {
return(paste(x, "what"));
}
drug.candidates <- unique(all.smiles.df$DrugName)
sapply(drug.candidates, test.func)
library("ChemmineR")
### Step 1: Load in date data.
clarivate.status.df <- read.csv('../data/wrds_clarivate_status.csv', stringsAsFactors = FALSE)
# Focus on dates from the US
clarivate.status.df.us.exclusive <- clarivate.status.df[clarivate.status.df$CountryID == "US", ]
# Get all unique rows to get our list, and then query to get our list of unique drugs who have reached at least phase 1.
unique.rows.clarivate.df <- unique(clarivate.status.df.us.exclusive[ ,c("DrugID", "DrugName", "DevelopmentStatus", "StatusDate")])
phase.1.drugs.with.date.df <- unique.rows.clarivate.df[unique.rows.clarivate.df$DevelopmentStatus=="Phase 1 Clinical", ]
phase.1.and.above.drugs.with.date <- unique.rows.clarivate.df[unique.rows.clarivate.df$DevelopmentStatus=="Phase 1 Clinical" |
unique.rows.clarivate.df$DevelopmentStatus=="Phase 2 Clinical" |
unique.rows.clarivate.df$DevelopmentStatus=="Phase 3 Clinical" |
unique.rows.clarivate.df$DevelopmentStatus=="Pre-registration" |
unique.rows.clarivate.df$DevelopmentStatus=="Registered" |
unique.rows.clarivate.df$DevelopmentStatus=="Launched", ]
#### Step 2: Load in SMILES data and join
full.processed.clarivate.df <- read.csv("../processed_data/wrds_clarivate_analytics_parsed_chem_structure_data_set.csv", stringsAsFactors = FALSE)
smiles.with.phase1.and.above.dates.df <- merge(x = full.processed.clarivate.df, y=phase.1.and.above.drugs.with.date, by="DrugName")
# all.smiles.df is the smiles data for all drugs, regardless of status
# indices.phase.1.plus is the indices of all.smiles.df that have reached phase1 and above.
all.smiles.df <- merge(x = full.processed.clarivate.df, y=clarivate.status.df.us.exclusive, by="DrugName")
indices.phase.1.plus <- which(all.smiles.df$DrugName %in% smiles.with.phase1.and.above.dates.df$DrugName)
smiles.phase.1.plus.df <- all.smiles.df[indices.phase.1.plus, ]
all.smiles.as.sdf <- smiles2sdf(all.smiles.df$StructureSMILES)
all.smiles.as.ap <- sdf2ap(all.smiles.as.sdf)
save(all.smiles.as.sdf, file = "all_smiles_as_sdf.rda", compress=TRUE)
save(all.smiles.as.ap, file = "all_smiles_as_ap.rda", compress = TRUE)
all.smiles.as.sdf
size(all.smiles.df)
dim(all.smiles.df)
dim(smiles.phase.1.plus.df)
length(all.smiles.as.ap)
tanimoto.coef.df <- data.frame("compound.1.name"=character(), "compound.2.name"=character(), "tanimoto.coefficient"=double())
for (i in 1:(length(all.smiles.as.ap))) {
for (j in indices.phase.1.plus) {
comp.1.name <- all.smiles.df$DrugName[i]
comp.2.name <- all.smiles.df$DrugName[j] # Compound 2 will always be the compound that has reached Phase 1+.
comp.1 <- compounds.as.sdf[i]
comp.2 <- compounds.as.sdf[j]
tanimoto.coef <- cmp.similarity(compounds.as.ap[i],compounds.as.ap[j])
if (tanimoto.coef >= 0.1 && comp.1.name != comp.2.name) {
tanimoto.coef.new.row <- data.frame(
"compound.1.name"=comp.1.name,
"compound.2.name"=comp.2.name,
"tanimoto.coefficient"=tanimoto.coef
)
tanimoto.coef.df <- rbind(tanimoto.coef.df, tanimoto.coef.new.row)
}
}
}
size(phase.1.and.above.drugs.with.date)
dim(phase.1.and.above.drugs.with.date)
tanimoto.coef.df <- data.frame("compound.1.name"=character(), "compound.2.name"=character(), "tanimoto.coefficient"=double())
for (i in 1:(length(all.smiles.as.ap))) {
for (j in indices.phase.1.plus) {
comp.1.name <- all.smiles.df$DrugName[i]
comp.2.name <- all.smiles.df$DrugName[j] # Compound 2 will always be the compound that has reached Phase 1+.
comp.1 <- all.smiles.as.sdf[i]
comp.2 <- all.smiles.as.sdf[j]
tanimoto.coef <- cmp.similarity(all.smiles.as.ap[i],all.smiles.as.ap[j])
if (tanimoto.coef >= 0.1 && comp.1.name != comp.2.name) {
tanimoto.coef.new.row <- data.frame(
"compound.1.name"=comp.1.name,
"compound.2.name"=comp.2.name,
"tanimoto.coefficient"=tanimoto.coef
)
tanimoto.coef.df <- rbind(tanimoto.coef.df, tanimoto.coef.new.row)
}
}
}
tanimoto.coef.df <- data.frame("compound.1.name"=character(), "compound.2.name"=character(), "tanimoto.coefficient"=double())
for (i in 1:(length(all.smiles.as.ap))) {
for (j in indices.phase.1.plus) {
comp.1.name <- all.smiles.df$DrugName[i]
comp.2.name <- all.smiles.df$DrugName[j] # Compound 2 will always be the compound that has reached Phase 1+.
comp.1 <- all.smiles.as.sdf[i]
comp.2 <- all.smiles.as.sdf[j]
if (comp.1.name != comp.2.name) {
tanimoto.coef <- cmp.similarity(all.smiles.as.ap[i],all.smiles.as.ap[j])
if (tanimoto.coef >= 0.1 && comp.1.name != comp.2.name) {
tanimoto.coef.new.row <- data.frame(
"compound.1.name"=comp.1.name,
"compound.2.name"=comp.2.name,
"tanimoto.coefficient"=tanimoto.coef
)
tanimoto.coef.df <- rbind(tanimoto.coef.df, tanimoto.coef.new.row)
}
}
}
}
tanimoto.coef.df
tanimoto.coef.df <- data.frame(compound.1.name=c("a", "b"), compound.2.name=c("e", "f"))
"e" %in% tanimoto.coef.df$compound.2.name && "a" %in% tanimoto.coef.df$compound.1.name
!("e" %in% tanimoto.coef.df$compound.2.name && "a" %in% tanimoto.coef.df$compound.1.name)
tanimoto.coef.df <- data.frame("compound.1.name"=character(), "compound.2.name"=character(), "tanimoto.coefficient"=double())
for (i in 1:(length(all.smiles.as.ap))) {
for (j in indices.phase.1.plus) {
comp.1.name <- all.smiles.df$DrugName[i]
comp.2.name <- all.smiles.df$DrugName[j] # Compound 2 will always be the compound that has reached Phase 1+.
comp.1 <- all.smiles.as.sdf[i]
comp.2 <- all.smiles.as.sdf[j]
# don't compute if the names are the same- will give us 1.
if (comp.1.name != comp.2.name) {
tanimoto.coef <- cmp.similarity(all.smiles.as.ap[i],all.smiles.as.ap[j])
if (tanimoto.coef >= 0.1 && comp.1.name != comp.2.name) {
tanimoto.coef.new.row <- data.frame(
"compound.1.name"=comp.1.name,
"compound.2.name"=comp.2.name,
"tanimoto.coefficient"=tanimoto.coef
)
tanimoto.coef.df <- rbind(tanimoto.coef.df, tanimoto.coef.new.row)
}
}
}
}
View(tanimoto.coef.df)
i
j
View(tanimoto.coef.df)
length(all.smiles.as.ap)
length(indices.phase.1.plus)
version
test.unbalanced.df <- read.csv("../data/test-unbalanced.csv")
train.balanced.df <- read.csv("../data/train-balanced-sarcasm.csv")
summary(test.unbalanced.df)
head(train.balanced.df)
head(test.unbalanced.df)
columns.desired <- c(NA, "NULL", "NULL", "NULL", NA, NA, NA, "NULL", "NULL", "NULL")
set.seed(14) # For deterministic output.
rm(list=ls())
library(data.table)
set.seed(14) # For deterministic output.
columns.desired <- c(NA, "NULL", "NULL", "NULL", NA, NA, NA, "NULL", "NULL", "NULL")
train.unbalanced.df <- fread(file="../data/train_unbalanced.csv", sep="\t", colClasses=columns.desired)
getwd()
file.directory <- dirname(parent.frame(2)$ofile)
setwd(getSrcDirectory()[1])
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
set.seed(14) # For deterministic output.
columns.desired <- c(NA, "NULL", "NULL", "NULL", NA, NA, NA, "NULL", "NULL", "NULL")
train.unbalanced.df <- fread(file="../data/train_unbalanced.csv", sep="\t", colClasses=columns.desired)
getwd()
setwd("D:/workspace")
setwd("CIS-520-Project/notebooks")
getwd()
set.seed(14) # For deterministic output.
columns.desired <- c(NA, "NULL", "NULL", "NULL", NA, NA, NA, "NULL", "NULL", "NULL")
train.unbalanced.df <- fread(file="../data/train_unbalanced.csv", sep="\t", colClasses=columns.desired)
set.seed(14) # For deterministic output.
columns.desired <- c(NA, "NULL", "NULL", "NULL", NA, NA, NA, "NULL", "NULL", "NULL")
train.unbalanced.df <- fread(file="../data/train-unbalanced.csv", sep="\t", colClasses=columns.desired)
rm(list=ls())
full.train.stats.df <- read.csv("../data/samples/train_unbalanced_statistics.csv")
set.seed(14) # For deterministic output.
sum.stats.cols <- c("label", "score", "ups", "downs", "comment.wc", "parent.comment.wc")
full.train.stats.df <- read.csv("../data/samples/train_unbalanced_statistics.csv", header=FALSE)
set.seed(14) # For deterministic output.
sum.stats.cols <- c("label", "score", "ups", "downs", "comment.wc", "parent.comment.wc")
full.train.stats.df <- read.csv("../data/samples/train_unbalanced_statistics.csv", header=FALSE)
colnames(full.train.stats.df) <- sum.stats.cols
summary(full.train.stats.df)
sampled.train.df <- read.csv("../data/sample_train_unbalanced.csv", header=FALSE, sep="\t")
sampled.train.df <- read.csv("../data/samples/sample_train_unbalanced.csv", header=FALSE, sep="\t")
train.schema <- c("label", "comment", "author", "subreddit", "score", "ups", "downs", "date", "created_utc", "parent_comment")
colnames(sampled.train.df) <- train.schema
get.word.count.of.comment <- function(comment) {
return(sapply(strsplit(comment, " "), length))
}
original.comment.wc <- sapply(sampled.train.df$comment, get.word.count.of.comment)
c()
original.comment.wc <- c()
for (i in 1:length(sampled.train.df)) {
wc <- get.word.count.of.comment(sampled.train.df$comment[i])
original.comment.wc <- c(original.comment.wc, wc)
}
sampled.train.df$comment[i]
original.comment.wc <- c()
for (i in 1:length(sampled.train.df)) {
wc <- get.word.count.of.comment(sampled.train.df$comment[i])
original.comment.wc <- c(original.comment.wc, wc)
}
sampled.train.df <- read.csv("../data/samples/sample_train_unbalanced.csv", header=FALSE, sep="\t", stringsAsFactors=FALSE)
train.schema <- c("label", "comment", "author", "subreddit", "score", "ups", "downs", "date", "created_utc", "parent_comment")
colnames(sampled.train.df) <- train.schema
get.word.count.of.comment <- function(comment) {
return(sapply(strsplit(comment, " "), length))
}
original.comment.wc <- c()
for (i in 1:length(sampled.train.df)) {
wc <- get.word.count.of.comment(sampled.train.df$comment[i])
original.comment.wc <- c(original.comment.wc, wc)
}
original.comment.wc <- c()
for (i in 1:length(sampled.train.df)) {
wc <- get.word.count.of.comment(sampled.train.df$comment[i])
original.comment.wc <- c(original.comment.wc, wc)
}
length(original.comment.wc)
length(sampled.train.df)
nrow(sampled.train.df)
original.comment.wc <- c()
for (i in 1:nrow(sampled.train.df)) {
wc <- get.word.count.of.comment(sampled.train.df$comment[i])
original.comment.wc <- c(original.comment.wc, wc)
}
train.schema <- c("label", "comment", "author", "subreddit", "score", "ups", "downs", "date", "created_utc", "parent.comment")
colnames(sampled.train.df) <- train.schema
all.comment.wc <- sapply(sampled.train.df$comment, get.word.count.of.comment)
all.parent.comment.wc <- sapply(sampled.train.df$parent.comment, get.word.count.of.comment)
length(all.comment.wc)
all.comment.wc[1:30]
all.comment.wc
sapply(strsplit("This is a comment", " "), length)
all.comment.wc[1:10]
all.comment.wc[1:10][[2]]
all.comment.wc <- c()
all.parent.comment.wc <- c()
for (i in 1:nrow(sampled.train.df)) {
all.comment.wc <- c(all.comment.wc, get.word.count.of.comment(sampled.train.df$comment[i]))
all.parent.comment.wc <- c(all.parent.comment.wc, get.word.count.of.comment(sampled.train.df$parent.comment[i]))
}
all.comment.wc <- rep(NA, nrow(sampled.train.df))
all.parent.comment.wc <- rep(NA, nrow(sampled.train.df))
for (i in 1:nrow(sampled.train.df)) {
all.comment.wc[i] <- get.word.count.of.comment(sampled.train.df$comment[i])
all.parent.comment.wc[i] <- get.word.count.of.comment(sampled.train.df$parent.comment[i])
}
sampled.train.df$comment.wc <- all.comment.wc
sampled.train.df$parent.comment.wc <- all.parent.comment.wc
sum.stats.sampled.train.df <- sampled.train.df[, c("label", "score", "ups", "downs", "comment.wc", "parent.comment.wc")]
sum.stats.sampled.train.df$label <- as.factor(sum.stats.sampled.train.df$label)
summary(sum.stats.sampled.train.df)
full.train.stats.df$label <- as.factor(full.train.stats.df$label)
summary(full.train.stats.df)
which(is.na(sum.stats.sampled.train.df$score))
sampled.train.df[2026907, ]
sampled.train.df[2026907, ]$label
sampled.train.df[2026907, ]$comment
sampled.train.df[2026908, ]$comment
sampled.train.df[2026908, ]
sampled.train.df[2026906, ]
sampled.train.df[2026907, ]
sampled.train.df[2026906, ]
sampled.train.df <- read.csv("../data/samples/sample_train_unbalanced.csv", header=FALSE, sep="\t", stringsAsFactors=FALSE)
train.schema <- c("label", "comment", "author", "subreddit", "score", "ups", "downs", "date", "created.utc", "parent.comment")
colnames(sampled.train.df) <- train.schema
head(sampled.train.df)
rm(full.train.stats.df)
data/samples/sample_train_unbalanced.csv", header=FALSE, sep="\t", stringsAsFactors=FALSE)
sampled.train.df <- read.csv("../data/samples/sample_train_unbalanced.csv", header=FALSE, sep="\t", stringsAsFactors=FALSE)
nrow(sampled.train.df)
sampled.train.df <- read.csv("../data/samples/sample_train_unbalanced.csv", header=FALSE, sep='\t', stringsAsFactors=FALSE)
rm(full.train.stats.df)
sampled.train.df <- read.csv("../data/samples/sample_train_unbalanced.csv", header=FALSE, sep='\t', stringsAsFactors=FALSE)
train.schema <- c("label", "comment", "author", "subreddit", "score", "ups", "downs", "date", "created.utc", "parent.comment")
colnames(sampled.train.df) <- train.schema
get.word.count.of.comment <- function(comment) {
return(sapply(strsplit(comment, " "), length))
}
all.comment.wc <- rep(NA, nrow(sampled.train.df))
all.parent.comment.wc <- rep(NA, nrow(sampled.train.df))
for (i in 1:nrow(sampled.train.df)) {
all.comment.wc[i] <- get.word.count.of.comment(sampled.train.df$comment[i])
all.parent.comment.wc[i] <- get.word.count.of.comment(sampled.train.df$parent.comment[i])
}
sampled.train.df$comment.wc <- all.comment.wc
sampled.train.df$parent.comment.wc <- all.parent.comment.wc
sum.stats.sampled.train.df <- sampled.train.df[, c("label", "score", "ups", "downs", "comment.wc", "parent.comment.wc")]
sum.stats.sampled.train.df$label <- as.factor(sum.stats.sampled.train.df$label)
summary(sum.stats.sampled.train.df)
129852191 + 505413
505413/130357604
12984640 + 50403
50403/13035043
