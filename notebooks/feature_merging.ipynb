{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading in everything and making the full feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = '../data/features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First loading in our CSVs\n",
    "\n",
    "def to_sparse_matrix(df):\n",
    "    return scipy.sparse.csc_matrix(df.values)\n",
    "\n",
    "pointedness_train_matr = to_sparse_matrix(pd.read_csv(os.path.join(data_base_dir, \"pointedness_train.csv\")))\n",
    "pointedness_test_matr = to_sparse_matrix(pd.read_csv(os.path.join(data_base_dir, \"pointedness_test.csv\")))\n",
    "\n",
    "synset_train_matr = to_sparse_matrix(pd.read_csv(os.path.join(data_base_dir, \"synset_train.csv\")))\n",
    "synset_test_matr = to_sparse_matrix(pd.read_csv(os.path.join(data_base_dir, \"synset_test.csv\")))\n",
    "\n",
    "frequency_train_matr = to_sparse_matrix(pd.read_csv(os.path.join(data_base_dir, 'frequency_train.csv')))\n",
    "frequency_test_matr = to_sparse_matrix(pd.read_csv(os.path.join(data_base_dir, 'frequency_test.csv')))\n",
    "\n",
    "sentiment_train_matr = to_sparse_matrix(pd.read_csv(os.path.join(data_base_dir, 'sentiment_train.csv')))\n",
    "sentiment_test_matr = to_sparse_matrix(pd.read_csv(os.path.join(data_base_dir, 'sentiment_test.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then loading in Artur's pattern work\n",
    "\n",
    "pattern_train = scipy.sparse.load_npz(os.path.join(data_base_dir, \"pattern_training.npz\"))\n",
    "pattern_test = scipy.sparse.load_npz(os.path.join(data_base_dir, \"pattern_test.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = [\n",
    "    pointedness_train_matr,\n",
    "    synset_train_matr,\n",
    "    frequency_train_matr,\n",
    "    sentiment_train_matr,\n",
    "    pattern_train\n",
    "]\n",
    "\n",
    "testing_features = [\n",
    "    pointedness_test_matr,\n",
    "    synset_test_matr,\n",
    "    frequency_test_matr,\n",
    "    sentiment_test_matr,\n",
    "    pattern_test\n",
    "]\n",
    "\n",
    "X_train_full = scipy.sparse.hstack(training_features)\n",
    "X_test_full = scipy.sparse.hstack(testing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1.1: Validating to ourselves that the output is what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3049316, 491)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(764172, 491)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1.2: Writing our full data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(open(os.path.join(data_base_dir, \"X_train_full.npz\"), \"wb+\"), arr=X_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(open(os.path.join(data_base_dir,\"X_test_full.npz\"), \"wb+\"), arr=X_test_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Thinning things out to make a more balanced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full = pd.read_csv('../data/samples/pol_train_cleaned.csv', sep='\\t')[['label']].values\n",
    "y_test_full = pd.read_csv('../data/samples/pol_test_cleaned.csv', sep='\\t')[['label']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0078657])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train_full)/X_train_full.shape[0] # Roughly 0.7% of our data is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00774695])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test_full)/X_test_full.shape[0] # And same with our testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15) # For deterministic output\n",
    "\n",
    "def get_more_balanced_data_set(X, y, prop_min=0.2):\n",
    "    '''\n",
    "    X: CSR Matrix of our features\n",
    "    y: Numpy array of our labels\n",
    "    prop_min: Float that represents what proportion of our data should be minority (at most)\n",
    "    \n",
    "    We're assuming the +1 class is positive.\n",
    "    '''\n",
    "    # Setting up how many negative classifications needed\n",
    "    num_positive = sum(y)[0]\n",
    "    num_total = X.shape[0]\n",
    "    num_majority_needed = (1-prop_min) * (num_positive/prop_min)\n",
    "    \n",
    "    # Getting our positively classified values\n",
    "    positive_indices = (y==1).flatten()\n",
    "    \n",
    "    # Getting our negatively classified values\n",
    "    negative_indices = (y==0).flatten()\n",
    "    # Then randomly removing rows until we get how many we need\n",
    "    frac_needed = num_majority_needed/(num_total * 1.0)\n",
    "    for i in range(len(negative_indices)):\n",
    "        uniform_distribution_draw = np.random.uniform()\n",
    "        if uniform_distribution_draw > frac_needed:\n",
    "            negative_indices[i] = False\n",
    "    \n",
    "    # Merging the two together\n",
    "    indices_desired = np.logical_or(positive_indices, negative_indices)\n",
    "    \n",
    "    # Extracting rows then returning.\n",
    "    return (X[indices_desired, ], y[indices_desired])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_full_csr = X_test_full.tocsr()\n",
    "X_train_full_csr = X_train_full.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_balanced, y_test_balanced = get_more_balanced_data_set(X_test_full_csr, y_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_balanced, y_train_balanced = get_more_balanced_data_set(X_train_full_csr, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119293, 491)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then to validate to ourselves this worked\n",
    "X_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29526, 491)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119293"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29526"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20105958])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train_balanced)/len(y_train_balanced) # Just about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20050125])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test_balanced)/len(y_test_balanced) # This too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then saving everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(open(os.path.join(data_base_dir, \"X_train_balanced.npz\"), \"wb+\"), arr=X_train_balanced)\n",
    "np.savez(open(os.path.join(data_base_dir,\"X_test_balanced.npz\"), \"wb+\"), arr=X_test_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(os.path.join(data_base_dir, \"y_train_balanced.npy\"), \"wb+\"), arr=y_train_balanced)\n",
    "np.save(open(os.path.join(data_base_dir,\"y_test_balanced.npy\"), \"wb+\"), arr=y_test_balanced)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
